{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjaSDYKM0xDD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5157360%2F8616644%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240606%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240606T111922Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1ca4d42356572fbefeb15d2cc37d1e95d8201d749098f4517ed9b14ede24f8154fd580937db2fc126103fc2dce2e0e35176b65c97424f97af8b6fe04ad6b94091a7cb414d6ec7f6e5595821307be106aa935a36553a6e0108553e3172e073499c94421037257071a8b38e075edff457920d4f5aed0c40f5e9df9e746d296e532e0cf8ff03d70d77f0a550caf365a50e6d910609f959aa4f41173e1dd75da93de70302487c6001bbce6756d1b1b0d00ad6955ffb2b33768f1ced92b4a1883f4dfa8f2931e69eba5e21697fbde50f30795503606c0f45dd2eb45421a0c7076bdf1bea21c32110d75b873c29ce0450417f801bd5e5b216626b1194fb978bdb3c19b'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "d_bZzt-F0xDW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAj-rNqX0xDa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/kaggle/input/dataset/clean_fused_dataset (2).csv\")\n",
        "# 'mark', 'model', 'price', 'isofix', 'led', 'cruise_control', 'bluetooth'\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fl75_zx0xDd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=[\"Unnamed: 0\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCHSFtsR0xDf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=[\"isautoscout\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TveSdVVo0xDh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEGL0h5x0xDk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_features = df.select_dtypes(exclude=['number']).columns.tolist()\n",
        "X = df.copy()\n",
        "\n",
        "for col in categorical_features:\n",
        "    X[col] = label_encoder.fit_transform(X[col])\n",
        "y = X[\"price\"]\n",
        "# X = X.drop(columns=[\"price\", \"description\"], axis=1)\n",
        "\n",
        "X = X.drop(columns=[\"price\"], axis=1)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsJyS4Fx0xDm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "len(df[\"description\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY_OS_dd0xDq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksuPrCZ20xDs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drl6Y0Y70xDx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "# rf_regressor.fit(X_train, y_train)\n",
        "# feature_importances = rf_regressor.feature_importances_\n",
        "# feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "# feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "# print(feature_importance_df)\n",
        "# y_pred = rf_regressor.predict(X_test)\n",
        "# mse = mean_absolute_error(y_test, y_pred)\n",
        "# print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zxyTwvm0xDz"
      },
      "source": [
        "# My features: mark, model, price, fuel, isofix, led, cruise_control, bluetooth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5YGJmBI0xD0"
      },
      "source": [
        "## mark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T61UfF7H0xD1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "category_counts = df['mark'].value_counts()\n",
        "plt.figure(figsize=(8, 8))  # Optional: Adjust the figure size\n",
        "plt.pie(category_counts, labels=df['mark'].unique(), autopct='%1.1f%%', startangle=140)\n",
        "plt.xlabel('Brands')\n",
        "plt.ylabel('Number of Cars')\n",
        "plt.title('Number of Rows for Each Brand')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7vZFJr70xD2"
      },
      "source": [
        "## Getting the brands under 1% of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVjngE2C0xD2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "category_counts = df['mark'].value_counts()\n",
        "category_counts[(category_counts / df.shape[0] *100) < 1] / df.shape[0] *100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bgirC0M0xD3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "minority_brands = category_counts[(category_counts / df.shape[0] *100) < 1].index.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7NP2AuB0xD3"
      },
      "source": [
        "## Groping the minority brands into a category called 'OTHERS'  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJPfEMHy0xD4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for b in minority_brands:\n",
        "    df.loc[df[\"mark\"] == b, \"mark\"] = \"OTHERS\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YrUnncD0xD5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "category_counts = df['mark'].value_counts()\n",
        "plt.figure(figsize=(8, 8))  # Optional: Adjust the figure size\n",
        "plt.pie(category_counts, labels=df['mark'].unique(), autopct='%1.1f%%', startangle=140)\n",
        "plt.xlabel('Brands')\n",
        "plt.ylabel('Number of Cars')\n",
        "plt.title('Number of Rows for Each Brand')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5tyvnSe0xD6"
      },
      "source": [
        "## Now we try to undersample the two brands \"RENAULT\", \"CITROEN\" and \"PEUGEOT\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjwHVWdf0xD6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "renault_indexes = df[df[\"mark\"] == \"RENAULT\"].index\n",
        "random_indices_renault = pd.Series(renault_indexes).sample(frac=0.5, random_state=42)\n",
        "df.drop(random_indices_renault, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFvOoXOw0xD7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "renault_indexes = df[df[\"mark\"] == \"CITROEN\"].index\n",
        "random_indices_renault = pd.Series(renault_indexes).sample(frac=0.5, random_state=42)\n",
        "df.drop(random_indices_renault, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zozhUF50xD7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "renault_indexes = df[df[\"mark\"] == \"PEUGEOT\"].index\n",
        "random_indices_renault = pd.Series(renault_indexes).sample(frac=0.5, random_state=42)\n",
        "df.drop(random_indices_renault, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mrPOwv80xD8"
      },
      "source": [
        "## We use oversampling for the brands under 5%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvTOD5W00xD8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "minority_brands_under_3 = category_counts[(category_counts / df.shape[0] *100) < 3].index.tolist()\n",
        "minority_brands_under_5 = category_counts[((category_counts / df.shape[0] *100) > 3) & ((category_counts / df.shape[0] *100) < 5)].index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0HLL0nI0xD8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for b in minority_brands_under_3:\n",
        "    brand_df = df[df[\"mark\"] == b]\n",
        "    brand_df = pd.concat([brand_df,brand_df] , axis=0, ignore_index=True)\n",
        "    df = pd.concat([df, brand_df], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azDS6D-F0xD9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for b in minority_brands_under_5:\n",
        "    brand_df = df[df[\"mark\"] == b]\n",
        "    df = pd.concat([df, brand_df], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ep5sTgO0xD-"
      },
      "source": [
        "## We see that the brands are far more balanced now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9Hy2as10xD-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "category_counts = df['mark'].value_counts()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(category_counts, labels=df['mark'].unique(), autopct='%1.1f%%', startangle=140)\n",
        "plt.xlabel('Brands')\n",
        "plt.ylabel('Number of Cars')\n",
        "plt.title('Number of Rows for Each Brand')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k0lMGdC0xD_"
      },
      "source": [
        "## model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr-xgbMQ0xD_"
      },
      "source": [
        "### This is the number of models for each brand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GYCsJA90xEA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_counts_by_brand = df.groupby('mark')['model'].nunique()\n",
        "print(model_counts_by_brand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH-gJ6LX0xEA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "model_counts_by_brand = df.groupby('mark')['model'].nunique().reset_index()\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(data=model_counts_by_brand, x='mark', y='model', palette='viridis')\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "plt.xlabel('Brand')\n",
        "plt.ylabel('Number of Models')\n",
        "plt.title('Number of Models for Each Brand')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc4wSzQc0xEB"
      },
      "source": [
        "## We are interested in \"DACIA\" as we can see, it has the second most numbers of samples but the least numbers of unique model values, this indicates that there are a lot of repititions in each of these models, let's find out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftS2GrIn0xED",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[df[\"mark\"] == \"DACIA\"][\"model\"].value_counts() / len(df[df[\"mark\"] == \"DACIA\"]) * 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVDw5t_O0xED",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dacia_model_distribution = df[df[\"mark\"] == \"DACIA\"][\"model\"].value_counts() / len(df[df[\"mark\"] == \"DACIA\"]) * 100\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(dacia_model_distribution, labels=dacia_model_distribution.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Model Distribution for DACIA')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGgxnckl0xEE"
      },
      "source": [
        "## We see that the model \"Sandero\" and \"Duster\" are overrepresented\n",
        "## We can use undersampling technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXCSiTA-0xEF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sandero_indices = df[df[\"model\"] == \"Sandero\"].index.tolist()\n",
        "random_sandero_indices = pd.Series(sandero_indices).sample(frac=0.8, random_state=42)\n",
        "df.drop(random_sandero_indices, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul1J_oiC0xEd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "duster_indices = df[df[\"model\"] == \"Duster\"].index.tolist()\n",
        "random_duster_indices = pd.Series(duster_indices).sample(frac=0.8, random_state=42)\n",
        "df.drop(random_duster_indices, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRicZn4A0xEf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dacia_model_distribution = df[df[\"mark\"] == \"DACIA\"][\"model\"].value_counts() / len(df[df[\"mark\"] == \"DACIA\"]) * 100\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(dacia_model_distribution, labels=dacia_model_distribution.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Model Distribution for DACIA')\n",
        "plt.axis('equal')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCzqw-wB0xEg"
      },
      "source": [
        "## We can oversample the models under 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGfTdZkH0xEh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "models_pourcentages = df[df[\"mark\"] == \"DACIA\"][\"model\"].value_counts() / len(df[df[\"mark\"] == \"DACIA\"]) * 100\n",
        "under_10_models = models_pourcentages[models_pourcentages < 10].index.tolist()\n",
        "for model in under_10_models:\n",
        "    df_added = df[df[\"model\"] == model]\n",
        "    df = pd.concat([df, df_added], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBGoOhKs0xEi"
      },
      "source": [
        "## We redo that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfy3spZf0xEj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "models_pourcentages = df[df[\"mark\"] == \"DACIA\"][\"model\"].value_counts() / len(df[df[\"mark\"] == \"DACIA\"]) * 100\n",
        "under_10_models = models_pourcentages[models_pourcentages < 10].index.tolist()\n",
        "for model in under_10_models:\n",
        "    df_added = df[df[\"model\"] == model]\n",
        "    df = pd.concat([df, df_added], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExDlRr_80xEk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dacia_model_distribution = df[df[\"mark\"] == \"DACIA\"][\"model\"].value_counts() / len(df[df[\"mark\"] == \"DACIA\"]) * 100\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(dacia_model_distribution, labels=dacia_model_distribution.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Model Distribution for DACIA')\n",
        "plt.axis('equal')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMgwVrnW0xEk"
      },
      "source": [
        "## The models are pretty balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDDRownp0xEl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_features = df.select_dtypes(exclude=['number']).columns.tolist()\n",
        "X = df.copy()\n",
        "for col in categorical_features:\n",
        "    X[col] = label_encoder.fit_transform(X[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7TioJjo0xEl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y = X[\"price\"]\n",
        "X = X.drop(columns=[\"price\", \"description\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYuVVWaT0xEm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "feature_importances = rf_regressor.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "print(feature_importance_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DJ0W2U50xEn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_pred = rf_regressor.predict(X_test)\n",
        "mse = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "953nD0Uw0xEo"
      },
      "source": [
        "# Price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drdX9mfe0xEo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df.index, df['price'], color='blue', alpha=0.5)  # Scatter plot\n",
        "plt.title('Scatter Plot of Price')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Price')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij77iM9Q0xEp"
      },
      "source": [
        "## We can spott some outliers in the price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paYkIkCf0xEr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot(df['price'])\n",
        "plt.title('Box Plot of Car Prices')\n",
        "plt.ylabel('Price')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9_DmWAj0xEs"
      },
      "source": [
        "## The boxplot highlights a very high imbalance in the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9_ks9gV0xEt"
      },
      "source": [
        "## Trying to filter the dataset from the outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK-kufC60xEu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Q1 = df['price'].quantile(0.25)\n",
        "Q3 = df['price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "df_clean = df[(df['price'] >= lower_bound) & (df['price'] <= upper_bound)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjeGDOeI0xEv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df_clean.index, df_clean['price'], color='blue', alpha=0.5)\n",
        "plt.title('Scatter Plot of Price')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Price')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tY4xn4o0xEw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_features = df_clean.select_dtypes(exclude=['number']).columns.tolist()\n",
        "X = df_clean.copy()\n",
        "for col in categorical_features:\n",
        "    X[col] = label_encoder.fit_transform(X[col])\n",
        "y = X[\"price\"]\n",
        "X = X.drop(columns=[\"price\", \"description\"], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "feature_importances = rf_regressor.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "print(feature_importance_df)\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "mse = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kktHuy5c0xEy"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMeawmvw0xEy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_Udb-Ys0xEz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWe35Rpv0xE0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "results_without_scaler = {'Model': [], 'MSE Train': [], 'MAE Train': [], 'R2 Train': [], 'MSE Test': [], 'MAE Test': [], 'R2 Test': []}\n",
        "results_with_scaler = {'Model': [],  'MSE Train': [], 'MAE Train': [], 'R2 Train': [], 'MSE Test': [], 'MAE Test': [], 'R2 Test': []}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeZNM6wy0xE1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def calculate_regression_metrics(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "    r2_train = r2_score(y_train, y_pred_train)\n",
        "    r2_test = r2_score(y_test, y_pred_test)\n",
        "    return mse_train,mae_train,r2_train,mse_test,mae_test,r2_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlkKNz4I0xE2"
      },
      "source": [
        "## Linear Regression :  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr2V1FiU0xE2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "linearRegression = Pipeline([('Linear Regression', LinearRegression())])\n",
        "mse_train,mae_train,r2_train,mse_test,mae_test,r2_teste = calculate_regression_metrics(linearRegression, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results_without_scaler['Model'].append('Linear Regression')\n",
        "results_without_scaler['MSE Train'].append(mse_train)\n",
        "results_without_scaler['MAE Train'].append(mae_train)\n",
        "results_without_scaler['R2 Train'].append(r2_train)\n",
        "results_without_scaler['MSE Test'].append(mse_test)\n",
        "results_without_scaler['MAE Test'].append(mae_test)\n",
        "results_without_scaler['R2 Test'].append(r2_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_Qa36Az0xE3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "linearRegression_withStandarisation = Pipeline([('scaler', StandardScaler()),('Linear Regression', LinearRegression())])\n",
        "mse_train,mae_train,r2_train,mse_test,mae_test,r2_teste = calculate_regression_metrics(linearRegression_withStandarisation, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results_with_scaler['Model'].append('Linear Regression')\n",
        "results_with_scaler['MSE Train'].append(mse_train)\n",
        "results_with_scaler['MAE Train'].append(mae_train)\n",
        "results_with_scaler['R2 Train'].append(r2_train)\n",
        "results_with_scaler['MSE Test'].append(mse_test)\n",
        "results_with_scaler['MAE Test'].append(mae_test)\n",
        "results_with_scaler['R2 Test'].append(r2_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0ZGx0Wz0xE4"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0ltaT_90xE4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "decisionTree = Pipeline([('Decision Tree', DecisionTreeRegressor())])\n",
        "mse_train,mae_train,r2_train,mse_test,mae_test,r2_teste = calculate_regression_metrics(decisionTree, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results_without_scaler['Model'].append('Decision Tree')\n",
        "results_without_scaler['MSE Train'].append(mse_train)\n",
        "results_without_scaler['MAE Train'].append(mae_train)\n",
        "results_without_scaler['R2 Train'].append(r2_train)\n",
        "results_without_scaler['MSE Test'].append(mse_test)\n",
        "results_without_scaler['MAE Test'].append(mae_test)\n",
        "results_without_scaler['R2 Test'].append(r2_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpfEGq2G0xE5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "decisionTree_with_scaler = Pipeline([('scaler', StandardScaler()),('Decision Tree', DecisionTreeRegressor())])\n",
        "mse_train,mae_train,r2_train,mse_test,mae_test,r2_teste= calculate_regression_metrics(decisionTree_with_scaler, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results_with_scaler['Model'].append('Decision Tree')\n",
        "results_with_scaler['MSE Train'].append(mse_train)\n",
        "results_with_scaler['MAE Train'].append(mae_train)\n",
        "results_with_scaler['R2 Train'].append(r2_train)\n",
        "results_with_scaler['MSE Test'].append(mse_test)\n",
        "results_with_scaler['MAE Test'].append(mae_test)\n",
        "results_with_scaler['R2 Test'].append(r2_teste)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j875R2r20xE6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok-9XfkG0xE6"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-jKlrL90xE7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "randomForest = Pipeline([('Random Forest', RandomForestRegressor())])\n",
        "mse_train,mae_train,r2_train,mse_test,mae_test,r2_teste= calculate_regression_metrics(decisionTree_with_scaler, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results_without_scaler['Model'].append('Random Forest')\n",
        "results_without_scaler['MSE Train'].append(mse_train)\n",
        "results_without_scaler['MAE Train'].append(mae_train)\n",
        "results_without_scaler['R2 Train'].append(r2_train)\n",
        "results_without_scaler['MSE Test'].append(mse_test)\n",
        "results_without_scaler['MAE Test'].append(mae_test)\n",
        "results_without_scaler['R2 Test'].append(r2_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um9ybcJY0xE8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "randomForest_with_scaler = Pipeline([('scaler', StandardScaler()),('Random Forest', RandomForestRegressor())])\n",
        "mse_train,mae_train,r2_train,mse_test,mae_test,r2_teste= calculate_regression_metrics(decisionTree_with_scaler, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results_with_scaler['Model'].append('Random Forest')\n",
        "results_with_scaler['MSE Train'].append(mse_train)\n",
        "results_with_scaler['MAE Train'].append(mae_train)\n",
        "results_with_scaler['R2 Train'].append(r2_train)\n",
        "results_with_scaler['MSE Test'].append(mse_test)\n",
        "results_with_scaler['MAE Test'].append(mae_test)\n",
        "results_with_scaler['R2 Test'].append(r2_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4CD1vGI0xE9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# models = [\n",
        "#     ('Linear Regression', LinearRegression()),\n",
        "#     ('Ridge Regression', Ridge()),\n",
        "#     ('Lasso Regression', Lasso()),\n",
        "#     ('Decision Tree', DecisionTreeRegressor()),\n",
        "#     ('Random Forest', RandomForestRegressor()),\n",
        "#     ('Gradient Boosting', GradientBoostingRegressor()),\n",
        "#     ('Support Vector Regressor', SVR()),\n",
        "#     ('K-Neighbors Regressor', KNeighborsRegressor()),\n",
        "#     ('Extra Trees', ExtraTreesRegressor()),\n",
        "#     # Uncomment the following line if you have xgboost installed\n",
        "#     # ('XGBoost', XGBRegressor())\n",
        "# ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HTdF6bU0xE9"
      },
      "source": [
        "## Support Vector Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDZep48A0xE-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "supportVectorRegressor = Pipeline([('Support Vector Regressor', SVR())])\n",
        "mse_train,mae_train,r2_train,mse_test,mae_test,r2_teste= calculate_regression_metrics(decisionTree_with_scaler, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results_without_scaler['Model'].append('Support Vector Regressor')\n",
        "results_without_scaler['MSE Train'].append(mse_train)\n",
        "results_without_scaler['MAE Train'].append(mae_train)\n",
        "results_without_scaler['R2 Train'].append(r2_train)\n",
        "results_without_scaler['MSE Test'].append(mse_test)\n",
        "results_without_scaler['MAE Test'].append(mae_test)\n",
        "results_without_scaler['R2 Test'].append(r2_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0fAKy0W0xE_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "supportVectorRegressor_with_scaler = Pipeline([('scaler', StandardScaler()),('Support Vector Regressor', SVR())])\n",
        "mse_train,mae_train,r2_train,mse_test,mae_test,r2_teste= calculate_regression_metrics(decisionTree_with_scaler, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results_with_scaler['Model'].append('Support Vector Regressor')\n",
        "results_with_scaler['MSE Train'].append(mse_train)\n",
        "results_with_scaler['MAE Train'].append(mae_train)\n",
        "results_with_scaler['R2 Train'].append(r2_train)\n",
        "results_with_scaler['MSE Test'].append(mse_test)\n",
        "results_with_scaler['MAE Test'].append(mae_test)\n",
        "results_with_scaler['R2 Test'].append(r2_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMnIUHOL0xFB"
      },
      "source": [
        "## lgbm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hAom_jy0xFC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "lgbm_model = LGBMRegressor()\n",
        "\n",
        "pipeline_without_scaling = Pipeline([('model', lgbm_model) ])\n",
        "mse_train,mae_train,r2_train,mse_test,mae_test,r2_teste= calculate_regression_metrics(pipeline_without_scaling, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results_without_scaler['Model'].append('lgbm')\n",
        "results_without_scaler['MSE Train'].append(mse_train)\n",
        "results_without_scaler['MAE Train'].append(mae_train)\n",
        "results_without_scaler['R2 Train'].append(r2_train)\n",
        "results_without_scaler['MSE Test'].append(mse_test)\n",
        "results_without_scaler['MAE Test'].append(mae_test)\n",
        "results_without_scaler['R2 Test'].append(r2_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRm4SPYE0xFD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "lgbm_model = LGBMRegressor()\n",
        "\n",
        "pipeline_without_scaling = Pipeline([('model', lgbm_model) ])\n",
        "mse_train,mae_train,r2_train,mse_test,mae_test,r2_teste= calculate_regression_metrics(pipeline_without_scaling, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results_without_scaler['Model'].append('lgbm')\n",
        "results_without_scaler['MSE Train'].append(mse_train)\n",
        "results_without_scaler['MAE Train'].append(mae_train)\n",
        "results_without_scaler['R2 Train'].append(r2_train)\n",
        "results_without_scaler['MSE Test'].append(mse_test)\n",
        "results_without_scaler['MAE Test'].append(mae_test)\n",
        "results_without_scaler['R2 Test'].append(r2_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZbaBP3H0xFE"
      },
      "source": [
        "## xgb_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hwd7qXm0xFF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have defined the dictionaries results_without_scaler and results_with_scaler\n",
        "\n",
        "# Convert dictionaries to DataFrames\n",
        "df_results_without_scaler = pd.DataFrame(results_without_scaler)\n",
        "df_results_with_scaler = pd.DataFrame(results_with_scaler)\n",
        "\n",
        "# Merge results for each model, keeping the same index\n",
        "df_results = pd.concat([df_results_without_scaler, df_results_with_scaler], axis=1)\n",
        "\n",
        "# Rename columns to differentiate between results with and without normalization\n",
        "columns_without_scaler = [f\"{col}\" for col in df_results_without_scaler.columns]\n",
        "columns_with_scaler = [f\"{col}\" for col in df_results_with_scaler.columns]\n",
        "df_results.columns = columns_without_scaler + columns_with_scaler\n",
        "\n",
        "# Display the combined DataFrame\n",
        "df_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-0k7ftH0xFG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Renommer les clés\n",
        "new_columns = {\n",
        "    'MSE Train': 'Train MSE',\n",
        "    'MAE Train': 'Train MAE',\n",
        "    'R2 Train': 'Train R2',\n",
        "    'MSE Test': 'Test MSE',\n",
        "    'MAE Test': 'Test MAE',\n",
        "    'R2 Test': 'Test R2'\n",
        "}\n",
        "\n",
        "df_results = df_results.rename(columns=new_columns)\n",
        "\n",
        "# Noms des algorithmes\n",
        "model_names = ['Linear Regression', 'Decision Tree', 'Random Forest', 'Support Vector Regressor']\n",
        "\n",
        "# Tracé des résultats de MSE\n",
        "plt.figure(figsize=(12, 6))\n",
        "df_results.filter(like='MSE').plot(kind='bar', width=0.8)\n",
        "plt.title('Mean Squared Error (MSE)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('MSE')\n",
        "plt.xticks(range(len(model_names)), model_names, rotation=45)\n",
        "plt.legend(title='Scaling')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Tracé des résultats de MAE\n",
        "plt.figure(figsize=(12, 6))\n",
        "df_results.filter(like='MAE').plot(kind='bar', width=0.8)\n",
        "plt.title('Mean Absolute Error (MAE)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks(range(len(model_names)), model_names, rotation=45)\n",
        "plt.legend(title='Scaling')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Tracé des résultats de R2\n",
        "plt.figure(figsize=(12, 6))\n",
        "df_results.filter(like='R2').plot(kind='bar', width=0.8)\n",
        "plt.title('R-squared (R2)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('R2')\n",
        "plt.xticks(range(len(model_names)), model_names, rotation=45)\n",
        "plt.legend(title='Scaling')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU9gDf9f0xFI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Supposons que vous ayez déjà défini les DataFrames df_results_without_scaler et df_results_with_scaler\n",
        "\n",
        "# Convertir les colonnes en listes\n",
        "columns_without_scaler = df_results_without_scaler.columns.tolist()\n",
        "columns_with_scaler = df_results_with_scaler.columns.tolist()\n",
        "\n",
        "# Supprimer la colonne \"Model\" car elle n'est pas une métrique\n",
        "columns_without_scaler.remove(\"Model\")\n",
        "columns_with_scaler.remove(\"Model\")\n",
        "\n",
        "# Afficher la différence entre les métriques pour chaque modèle\n",
        "for model_name in df_results_without_scaler[\"Model\"]:\n",
        "    print(f\"Model: {model_name}\")\n",
        "    for col_without_scaler, col_with_scaler in zip(columns_without_scaler, columns_with_scaler):\n",
        "        difference = df_results_with_scaler.loc[df_results_with_scaler[\"Model\"] == model_name, col_with_scaler].values[0] - df_results_without_scaler.loc[df_results_without_scaler[\"Model\"] == model_name, col_without_scaler].values[0]\n",
        "        print(f\"{col_with_scaler} - {col_without_scaler}: {difference}\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6KP9ypG0xFJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Métriques et leurs différences\n",
        "metrics = ['MSE Train', 'MAE Train', 'R2 Train', 'MSE Test', 'MAE Test', 'R2 Test']\n",
        "\n",
        "\n",
        "# Plot\n",
        "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Metrics standarisation - Metrics sans standarisation')\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    axs[row, col].bar(difference.keys(), [diff[i] for diff in difference.values()])\n",
        "    axs[row, col].set_title(metric)\n",
        "    axs[row, col].set_ylabel('Difference')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZmAGdmX0xFK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(\"Length of lists in results_without_scaler:\")\n",
        "for key, value in results_without_scaler.items():\n",
        "    print(f\"{key}: {len(value)}\")\n",
        "\n",
        "print(\"\\nLength of lists in results_with_scaler:\")\n",
        "for key, value in results_with_scaler.items():\n",
        "    print(f\"{key}: {len(value)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ2Cqqb10xFL"
      },
      "source": [
        "\n",
        "## Linear Regression:\n",
        "\n",
        "Performance : Ce modèle montre les MSE et MAE les plus élevés pour les ensembles d'entraînement et de test, indiquant une mauvaise performance.\n",
        "\n",
        "Raison : La régression linéaire peut ne pas capturer la complexité des données en raison de sa simplicité et de sa linéarité.\n",
        "\n",
        "## Polynomial Regression:\n",
        "\n",
        "Performance : Amélioration par rapport à la régression linéaire avec des MSE et MAE plus bas, et un 𝑅2 plus élevé.\n",
        "\n",
        "Raison : La régression polynomiale capture une partie de la non-linéarité mais peut encore être insuffisante pour les schémas de données très complexes.\n",
        "\n",
        "## Decision Tree:\n",
        "\n",
        "Performance : Excellente performance d'entraînement (presque zéro erreur)\n",
        "\n",
        "Raison : Les arbres de décision ont tendance à surajuster les données d'entraînement mais en remarque pas ce probleme dans ce cas\n",
        "\n",
        "## Random Forest:\n",
        "\n",
        "Performance : Performance de test légèrement meilleure comparée à un seul arbre de décision, avec des MSE, MAE et 𝑅2 équilibrés.\n",
        "\n",
        "Raison : La forêt aléatoire réduit le surapprentissage en moyennant plusieurs arbres de décision, ce qui conduit à une meilleure généralisation\n",
        "\n",
        "## Support Vector Regressor (SVR):\n",
        "\n",
        "Performance : Comparable à la forêt aléatoire avec des métriques légèrement différentes, montrant une bonne généralisation.\n",
        "\n",
        "Raison : Le SVR peut gérer efficacement les données de haute dimension et offre un bon équilibre entre biais et variance.\n",
        "\n",
        "\n",
        "## Sélection du Meilleur Modèle:\n",
        "\n",
        "Support Vector Regressor est le meilleur modèle parmi ceux évalués. Elle offre un bon équilibre entre les performances d'entraînement et de test, comme indiqué par le MSE et le MAE relativement bas sur le jeu de test et une valeur 𝑅2 élevée. La capacité de Support Vector Regressore à réduire le surapprentissage et à capturer des schémas complexes dans les données en fait un choix approprié.\n",
        "\n",
        "## Conclusion:\n",
        "\n",
        "Régression Linéaire et Régression Polynomiale : Pas adaptées en raison des taux d'erreur élevés.\n",
        "\n",
        "random forest ,Desicion tree : Également un bon choix mais la forêt aléatoire est légèrement meilleure en termes de métriques globales\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "cars_data_visualisation",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4981995,
          "sourceId": 8378264,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5157360,
          "sourceId": 8616644,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30698,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
